Vast.ai Serverless PyWorker アーキテクチャと実装：動的ワーカー状態管理とオートスケーリング機構に関する包括的技術レポート1. 序論：分散型サーバーレス推論のパラダイムシフト現代のAIインフラストラクチャにおいて、大規模言語モデル（LLM）や生成AIワークロードの爆発的な増加は、従来の静的なGPUレンタルモデルから、より動的で柔軟な「サーバーレス」アーキテクチャへの移行を強く促しています。しかし、AWS LambdaやGoogle Cloud Runのような従来の中央集権型ハイパースケーラーが提供するサーバーレスソリューションとは異なり、Vast.aiは分散型マーケットプレイスの上に構築された独自のサーバーレスエコシステムを展開しています。このシステムの中核を成すのが「PyWorker」と呼ばれるインテリジェントなエージェントソフトウェアです。本レポートでは、Vast.aiのサーバーレスプラットフォームにおけるPyWorkerの役割、特にワーカーが「Active（稼働可能）」な状態をどのように中央オートスケーラーに報告するのか、その通信メカニズムであるREPORT_ADDR環境変数の詳細、そして異種混合なハードウェア環境において信頼性を担保するためのベンチマークハンドラーおよびカスタムヘルスチェックの実装について、徹底的な技術分析を行います。この分析は、単なる機能解説にとどまらず、分散システムにおける状態管理の設計思想や、予測的オートスケーリングを実現するためのメトリクス収集の深層にまで踏み込みます。1.1 中央集権型と分散型のエージェントモデルの比較従来のクラウドプロバイダーでは、インフラストラクチャの管理は完全に不透明な「ブラックボックス」として提供されます。対照的に、Vast.aiは世界中に分散したGPUリソースを束ねるマーケットプレイスモデルを採用しており、ハードウェアの性能や信頼性は均一ではありません。この不均一性を抽象化し、ユーザーに対して統一された「サーバーレス」体験を提供するために、Vast.aiは各GPUインスタンス上で動作するPyWorkerに高度な自律性を与えています1。PyWorkerは単なるリクエストプロキシではなく、自己の状態を監視し、性能を測定し、その結果を中央システムに報告する「アクティブエージェント」として機能します。このアーキテクチャにより、Vast.aiは物理的に離れた場所にある多様なGPU（例えば、コンシューマー向けのRTX 4090からエンタープライズ向けのA100まで）を、単一の論理的なエンドポイントとして統合することが可能になります3。1.2 本レポートの構成本稿では以下の技術的要素について詳述します。PyWorkerのアーキテクチャ: モデル推論サーバーとのサイドカー構成および内部通信フロー。Ready状態の報告メカニズム: REPORT_ADDRを用いたハートビート通信と初期化シーケンス。サーバーレスベンチマークハンドラー: make_benchmark_payloadメソッドによる動的性能測定の実装詳細。カスタムエンドポイントハンドラーとヘルスチェック: EndpointHandlerクラスを用いた信頼性担保と障害検知ロジック。オートスケーリングとの統合: 収集されたメトリクスがどのようにスケーリング決定（cold_mult, min_load）に影響を与えるか。2. PyWorkerアーキテクチャの深層分析Vast.aiのサーバーレス環境における「Active Worker Condition（アクティブワーカー条件）」を理解するためには、まずPyWorkerがシステム全体の中でどのような位置づけにあるかを把握する必要があります。PyWorkerは、ユーザーがデプロイする機械学習モデル（バックエンド）と、Vast.aiの中央制御プレーン（オートスケーラー/ディスパッチャー）との間を取り持つ仲介者として設計されています。2.1 サイドカープロキシとしての役割技術的な観点から見ると、PyWorkerはPythonベースの非同期ウェブサーバー（主にaiohttpを使用）であり、GPUインスタンス上のDockerコンテナ内で実行されます。その主な責務は以下の通りです3。リクエストの受信と転送: クライアントからの推論リクエストを受け取り、同一インスタンス内で稼働しているモデルAPI（例：vLLMやTGIがリッスンしているlocalhost:8000）へ転送します。レスポンスの返却: モデルからの出力を受け取り、必要に応じてフォーマットを調整した上でクライアントへ返却します。メトリクスの集計: 処理中のリクエスト数、処理時間、トークン生成速度などのパフォーマンス指標をリアルタイムで計測します。状態の自律報告: 自身の健康状態と負荷状況を周期的に中央システムへ送信します。この設計において重要なのは、PyWorkerがモデルサーバーとは独立したプロセスとして動作している点です。これにより、モデルサーバーがクラッシュした場合や応答不能に陥った場合でも、PyWorker自体は稼働し続け、エラー状態を外部に報告することが可能になります。これは分散システムの可観測性（Observability）を確保する上で極めて重要な設計思想です。2.2 ディレクトリ構造とコンポーネントPyWorkerのソースコード構造は、その機能的役割を明確に反映しています3。lib/: コアフレームワークコードが含まれています。サーバーロジック、データ型定義、メトリクス計算、バックエンド通信の基盤クラスがここに集約されています。workers/: 特定のモデルサーバー（バックエンド）に対応した実装が含まれています。例えば、workers/tgi/やworkers/comfyui/のようなサブディレクトリが存在し、それぞれのバックエンドAPI仕様に合わせたアダプターコードが配置されています。start_server.sh: コンテナ起動時に実行されるエントリポイントであり、環境変数の設定やPyWorkerプロセスの立ち上げを担います3。2.3 クライアント・システム・ワーカーの三角通信Vast.aiのサーバーレスリクエストフローは、一般的なロードバランサー構成とは異なる独特な「三角通信」パターンを採用しています1。ディスカバリ（Discovery）: クライアントはまず、Vast.aiのサーバーレスシステムのエンドポイント（/route/）に対してPOSTリクエストを送信します。ルーティング（Selection）: システムは、現在の負荷状況と各ワーカーから報告されたステータスに基づき、利用可能な最適なワーカーインスタンスを選択し、そのURLと認証情報をJSONオブジェクトとしてクライアントに返却します。ダイレクトアクセス（Execution）: クライアントは受け取ったURL（特定のGPUインスタンスのアドレス）に対して、直接ペイロードを送信します。フィードバック（Feedback）: リクエストを処理したPyWorkerは、その結果やパフォーマンスメトリクスを非同期にシステムへ報告し、次回のルーティング決定に反映させます。このアーキテクチャにより、中央システムのボトルネックを最小限に抑えつつ、クライアントとGPU間の低遅延な通信を実現しています。しかし、この仕組みが機能するためには、ワーカーが自身のアドレスと稼働状況を正確かつタイムリーにシステムへ登録（報告）していることが絶対条件となります。ここでREPORT_ADDRの役割が決定的となります。3. Active Worker条件とReadyステータスの報告メカニズム「Active Worker」とは、単にコンテナが起動している状態を指すのではありません。Vast.aiのエコシステムにおいて、ワーカーがActiveであると見なされるためには、モデルがメモリにロードされ、推論APIが応答可能であり、かつその状態が正しくオートスケーラーに認識されている必要があります。この一連のプロセスを制御するのが、PyWorkerの状態報告メカニズムです。3.1 初期化シーケンスと状態遷移インスタンスがプロビジョニングされた直後、PyWorkerは以下のようなシーケンスを経て「Ready」状態へと遷移します。起動（Startup）: Dockerコンテナが起動し、start_server.shが実行されます。この時点でPyWorkerプロセスが立ち上がりますが、内部ステータスは「Loading」または「Initializing」です。バックエンド待機（Backend Wait）: PyWorkerは、localhost上のモデルサーバー（例：ポート8000）に対してポーリングを行い、接続確立を試みます。巨大なLLMの場合、モデルの重みデータをVRAMに展開するのに数分かかる場合があり、その間PyWorkerは接続試行を繰り返します。ベンチマーク実行（Benchmarking）: バックエンドとの接続が確立されると、多くの実装では即座に性能測定（ベンチマーク）が実行されます。これは、そのハードウェアが実際にどの程度の処理能力を持っているかを確定させるためです（詳細は第5章で後述）。Ready報告: ベンチマークが完了し、正常な動作が確認されると、PyWorkerは内部ステータスを「Ready」または「Idle」に変更し、この情報をREPORT_ADDRへ送信します1。3.2 REPORT_ADDR環境変数の詳細と実装REPORT_ADDR環境変数は、PyWorkerが外部のVast.ai制御プレーンと通信するための唯一の接点です。この変数の重要性はどれほど強調してもし過ぎることはありません。3.2.1 変数の注入と構造この環境変数は、ユーザーが手動で設定するものではなく、Vast.aiのオーケストレーションシステムによってコンテナ起動時に自動的に注入されます。内容: 通常、特定のオートスケーラーインスタンスまたはロードバランサーのエンドポイントURL（例: https://autoscaler-us-west.vast.ai/update_status/...）が格納されています。セキュリティ: このURLには、特定のワーカーグループやインスタンスを識別するためのトークンやパスが含まれている場合があり、これを知ることでワーカーはそのグループの一員としての正当性を証明します。3.2.2 ハートビート送信ループの実装PyWorkerの内部（lib/server.py周辺）では、asyncioを用いた無限ループが実装されており、これが「ハートビート」として機能します。Python# 概念的な実装イメージ（実際のコードは非公開部分を含む可能性があります）
async def report_status_loop(self):
    while True:
        try:
            # 現在のメトリクスとステータスを収集
            payload = self.gather_metrics()
            target_url = os.environ.get('REPORT_ADDR')

            if target_url:
                async with aiohttp.ClientSession() as session:
                    await session.post(target_url, json=payload)
            
            # 定期的な待機（例: 数秒ごと）
            await asyncio.sleep(self.report_interval)
        except Exception as e:
            logger.error(f"Failed to report status: {e}")
このループが正常に回っている限り、オートスケーラーはそのワーカーを「生存（Alive）」と見なします。逆に、ネットワーク障害やコンテナのクラッシュによってこのPOSTリクエストが途絶えると、システムはワーカーを「Unhealthy」または「Offline」と判断し、ルーティング対象から除外します。3.3 Readyステータスの重要性と「Cold Workers」Vast.aiのサーバーレス設定にはcold_workersというパラメータが存在します5。これは、「停止しているがモデルがロードされており、即座に起動可能なワーカー」の最小数を定義するものです。重要な洞察として、ワーカーがこの「Cold」プールにカウントされるためにも、一度は完全に起動し、モデルをロードし、REPORT_ADDRを通じて「私は準備完了です（Ready）」と報告する必要があります。つまり、初期化に失敗したり、報告メカニズムに不備があるカスタムワーカーは、Coldスタンバイとしてすら機能せず、システムによって破棄される可能性があります。したがって、カスタムPyWorkerを開発する際は、REPORT_ADDRへの到達性を確保することが最初のマイルストーンとなります。4. サーバーレスベンチマークハンドラーの実装と役割Vast.aiのプラットフォームが他のクラウドと大きく異なる点は、ハードウェアの多様性にあります。同じ「RTX 3090」であっても、ホストマシンのCPU性能、PCIeのレーン数（x16 vs x4）、システムメモリの速度、あるいは熱設計によって、実際の推論性能は大きく異なります。このため、静的なスペック情報だけでは適切な負荷分散が不可能です。そこで登場するのが「サーバーレスベンチマークハンドラー」です。4.1 静的指標（DLPerf）と動的指標（Measured Perf）Vast.aiは「DLPerf」という静的なスコアリングシステムを持っています6。これは一般的なディープラーニングタスク（ResNet50など）における性能を推定した値です。しかし、実際のサーバーレスワークロード（特定のLLMの推論や画像生成）における性能は、DLPerfとは必ずしも相関しません。そのため、PyWorkerはアプリケーション固有の動的ベンチマークを実施します。これによって得られる値がmeasured_perfであり、オートスケーラーはこの値を最も信頼できる指標として扱います7。4.2 make_benchmark_payloadメソッドの詳解動的ベンチマークの中核となるのが、EndpointHandlerクラスにおけるmake_benchmark_payloadメソッドの実装です3。カスタムワーカーを作成する開発者は、このメソッドを必ずオーバーライドして実装しなければなりません。4.2.1 メソッドの役割と実装要件make_benchmark_payload(self)は引数を取らず、バックエンドモデルが処理可能な「標準的なリクエストペイロード」を返却する必要があります。目的: 実際のユーザーリクエストを模倣したダミーリクエストを作成すること。戻り値: InputDataオブジェクト、またはバックエンドAPIが期待するJSON互換の辞書データ8。4.2.2 実装の具体例（LLMの場合）LLM（vLLMやTGI）のワーカーにおいて、このメソッドは以下のようなペイロードを生成します。プロンプト: 短すぎず長すぎない、決定論的な出力が期待できる入力（例: "1から50まで数えてください"）。パラメータ: max_tokensを固定値（例: 100トークン）に設定し、temperatureなどのランダム要素を排除する設定が推奨されます。これにより、ベンチマークの再現性が確保されます。Python# 概念的な実装例
def make_benchmark_payload(self):
    return {
        "inputs": "Calculate the square root of 256.",
        "parameters": {
            "max_new_tokens": 50,
            "temperature": 0.1
        }
    }
4.3 ベンチマーク実行プロセスとパフォーマンス算出PyWorkerが起動すると、以下のフローでベンチマークが実行されます。呼び出し: 初期化シーケンスの中でmake_benchmark_payloadが呼び出され、テスト用データが生成されます。推論実行: このデータは、ユーザーリクエストと同様の経路（generate_client_responseメソッドなど）を通じてバックエンドモデルへ送信されます。時間計測: PyWorkerは、リクエスト送信からレスポンス受信までの時間を高精度タイマーで計測します。スループット計算: 生成されたトークン数や処理された画像枚数を所要時間で割り、スループット（例: Tokens Per Second, Images Per Second）を算出します。報告: この算出された値がmeasured_perfとして内部状態に保存され、次回のREPORT_ADDRへのハートビートに含まれて送信されます。4.4 オートスケーリングへの影響このmeasured_perfは、オートスケーラーが「このインスタンスはどれだけの負荷（リクエスト）を処理できるか」を判断する基準となります。もしmake_benchmark_payloadが実装されていない、あるいは不適切な値を返した場合、measured_perfは0または不正な値となり、オートスケーラーはこのワーカーにリクエストを割り振らない可能性があります。逆に、正確なベンチマークが行われることで、高性能なマシンには多くのリクエストが、低性能なマシンには少ないリクエストが配分されるようになり、全体のレイテンシとコスト効率が最適化されます9。5. カスタムエンドポイントハンドラーとヘルスチェック機構PyWorkerの柔軟性は、開発者が独自のモデルやAPI仕様に合わせてEndpointHandlerをカスタマイズできる点にあります。特に、システムの信頼性を維持するための「ヘルスチェック（Health Check）」の実装は、本番運用において極めて重要です。5.1 EndpointHandlerクラスの構造lib.data_types.EndpointHandlerは、PyWorkerが特定のリクエストパス（URL）をどのように処理するかを定義する基底クラスです3。以下のメソッドをオーバーライドすることで、カスタムロジックを実装します。endpoint(self): このハンドラーが担当するAPIパス（例: /generate, /health）を返します。payload_cls(self): リクエストボディのバリデーションに使用するデータクラスを指定します。generate_client_response(self, payload): クライアントへのレスポンス生成ロジックを記述します。ここでバックエンドへの通信を行います。5.2 ヘルスチェックの二層構造Vast.ai環境におけるヘルスチェックは、単純な「生死確認」以上の意味を持ちます。それは「内部的整合性」と「外部的可用性」の二層で構成されています。5.2.1 内部ヘルスチェック（Internal Consistency）これは、PyWorkerがバックエンドモデルに対して行うチェックです。カスタムハンドラーを作成する際、開発者は/healthのような専用エンドポイントを実装することが推奨されます。実装戦略: endpointメソッドで/healthを返し、generate_client_response内でバックエンドのヘルスAPI（例: http://localhost:8000/health）へ軽いリクエストを送ります。重要性: バックエンドプロセスがゾンビ状態（プロセスは存在するが応答しない）になっている場合、OSレベルの監視だけでは不十分です。アプリケーションレベルでの応答確認が必要です。5.2.2 外部ヘルスチェック（Status Reporting）これは、PyWorkerがREPORT_ADDRを通じてオートスケーラーに報告するステータスです。連動: 内部ヘルスチェックが失敗した場合（例: バックエンドからの応答がタイムアウト）、PyWorkerはエラーを捕捉し、オートスケーラーへの報告ペイロード内のstatusフィールドを「Error」や「Unhealthy」に変更すべきです。自動復旧: オートスケーラーはこの報告を受け取ると、当該インスタンスをルーティングから外し、設定によってはコンテナの再起動（Restart）やインスタンスの破棄（Destroy）と再作成をトリガーします。5.3 障害対応と信頼性スコア（Reliability）Vast.aiは各ワーカーに対してreliability（信頼性）というスコア（0.0〜1.0）を付与しています7。これは、ワーカーの稼働時間と正常応答率に基づいています。カスタムハンドラーの影響: エンドポイントハンドラー内で予期せぬ例外が発生すると、それは「処理失敗」としてカウントされ、信頼性スコアを低下させます。ベストプラクティス: generate_client_response内では適切な例外処理を行い、一時的なエラー（ネットワークの瞬断など）と致命的なエラー（モデルのクラッシュ）を区別して報告することが、高い信頼性スコアを維持するために不可欠です。6. オートスケーラー統合とメトリクスによる制御PyWorkerが収集・報告した情報は、Vast.aiの中央オートスケーラーによって解析され、フリート全体のスケーリング決定に使用されます。この章では、具体的なメトリクスとスケーリングパラメータの相互作用について解説します。6.1 主要な報告メトリクスREPORT_ADDRへ送信されるJSONペイロードには、以下の主要なメトリクスが含まれています7。メトリクス名説明役割cur_load現在の負荷（例: tokens/sec）リアルタイムのスケーリングトリガーreqs_working現在処理中のリクエスト数同時実行数の把握measured_perfベンチマーク結果ワーカーの最大容量の定義status現在の状態（idle, busy, loading）ルーティング可否の判定reliability稼働信頼性スコアインスタンスの継続利用判断6.2 スケーリングロジックの数理：cold_multとmin_loadオートスケーラーは、これらのメトリクスとユーザーが設定したパラメータ（cold_mult, min_load, target_util）を組み合わせて、必要なワーカー数を算出します5。6.2.1 目標容量（Target Capacity）の算出システムは、将来の需要を見越してどれだけのリソースを確保すべきかを以下のように計算します（概念式）。$$TargetCapacity = (CurrentLoad \times ColdMult) + MinLoad$$min_load: 実際のトラフィックがゼロであってもシステムが維持しようとする「最低保証容量」です。これにより、突然のリクエストスパイクに対する初期応答能力（ベースロード）が確保されます。cold_mult: 現在の負荷に対する「予備係数」です。例えば負荷が100でcold_multが2.5の場合、システムは250の容量を確保しようとします。これは長期的な（1時間以上の）キャパシティプランニングに使用されます。6.2.2 容量の充足判定次に、システムは現在のフリート全体の容量を計算します。$$TotalCapacity = \sum (ActiveWorkers \times MeasuredPerf) + \sum (ColdWorkers \times MeasuredPerf)$$ここでmeasured_perf（ベンチマーク結果）が重要になります。もしワーカーごとの性能が低く見積もられている場合、システムはより多くのワーカーを必要と判断し、コストが増加する可能性があります。逆に高く見積もられすぎていると、実際の負荷に耐えられずレイテンシが悪化します。正確なmake_benchmark_payloadの実装が、コストと性能のバランスに直結するのです。6.3 テンプレートと環境変数の役割PyWorkerの動作を制御するために、テンプレート設定や環境変数が活用されます11。MODEL_NAME: 多くのテンプレート（vLLMなど）で使用され、ロードするモデルを指定します。PyWorkerはこの情報を基に、初期化の完了判定ロジックを調整する場合があります。HF_TOKEN: Hugging Faceの認証トークン。プライベートモデルを使用する場合に必須であり、これが設定されていないとモデルダウンロードに失敗し、PyWorkerは永遠にReady状態になれません。MAX_WORKERS: スケーリングの上限設定。無限の課金を防ぐための安全装置として機能します5。7. 実践的実装ガイド：カスタムPyWorkerの開発手順これまでの分析に基づき、実際にVast.aiサーバーレス環境で動作する堅牢なカスタムPyWorkerを開発するためのステップバイステップガイドを提示します。7.1 ディレクトリとファイルの準備まず、workers/ディレクトリ配下に新しいサブディレクトリ（例: workers/my_custom_model/）を作成します。ここに最低限必要なファイルは以下の通りです3。__init__.py: 空ファイル（Pythonパッケージとして認識させるため）。data_types.py: データ構造定義。server.py: メインロジック。test_load.py: ローカルテスト用スクリプト（任意だが推奨）。7.2 data_types.pyの実装ここでは、リクエストのペイロード構造を定義します。Pythonimport dataclasses
from lib.data_types import ApiPayload

@dataclasses.dataclass
class MyModelPayload(ApiPayload):
    prompt: str
    max_tokens: int = 100

    def count_workload(self):
        # オートスケーラーに報告する負荷量（トークン数など）を計算
        return self.max_tokens
count_workloadメソッドの実装は重要です。これにより、オートスケーラーはリクエストごとの重みを理解し、cur_loadを正確に計算できるようになります。7.3 server.pyの実装（核心部）ここでEndpointHandlerとベンチマーク、ヘルスチェックを統合します。Pythonfrom lib.data_types import EndpointHandler
from.data_types import MyModelPayload
import lib.server
import lib.backend

class MyModelHandler(EndpointHandler):
    def endpoint(self):
        return "/generate"

    def payload_cls(self):
        return MyModelPayload

    def make_benchmark_payload(self):
        # ベンチマーク用の軽量リクエストを生成
        return MyModelPayload(prompt="Benchmark test", max_tokens=10)

    async def generate_client_response(self, payload):
        # バックエンドへのリクエスト送信ロジック
        # ここでエラーハンドリングを行うことが重要
        try:
            response = await self.backend.client.post(...)
            return response
        except Exception as e:
            # エラーログを出力し、例外を再送出することでシステムに異常を伝える
            raise e

def start_server():
    # バックエンドの定義（localhost:8000を想定）
    backend = lib.backend.Backend(
        model_server_url="http://localhost:8000",
        model_log_path="/var/log/model.log"
    )
    # ハンドラーの登録
    backend.create_handler(MyModelHandler)
    # サーバーの起動
    lib.server.start_server(backend)

if __name__ == "__main__":
    start_server()
7.4 ローカルテストとデプロイ実装後は、test_load.pyを使用してローカル環境あるいは単一のVastインスタンス上で負荷テストを行います3。このテストでは、REPORT_ADDRへの通信はシミュレートされるか無視されますが、バックエンドとの通信やベンチマークロジックが正常に機能するかを確認できます。確認後、このコードを含むDockerイメージを作成し、Vast.aiのテンプレート設定画面で「Docker Image」として指定します。さらに、テンプレート設定で「Launch Mode」を「Serverless」に設定し、必要な環境変数を入力することで、カスタムワーカーがフリートの一部として稼働し始めます。8. 結論：スマートワーカーによるエコシステムの最適化Vast.aiのPyWorkerアーキテクチャは、従来の中央集権的なクラウド管理手法とは一線を画す「スマートワーカー（Smart Worker）」アプローチを採用しています。ベンチマーク実行、ヘルスチェック、ステータス報告といったインテリジェンスを個々のワーカーエージェント（PyWorker）に委譲することで、Vast.aiは極めて異質で多様なGPUハードウェア群を、単一の一貫性のあるサーバーレスプラットフォームとして抽象化することに成功しています。開発者にとって、このアーキテクチャを理解することは極めて重要です。REPORT_ADDRによる通信プロトコルを遵守し、正確なmake_benchmark_payloadを実装し、堅牢なEndpointHandlerによるヘルスチェック機構を構築することで初めて、Vast.aiの強力なオートスケーリング機能の恩恵を最大限に享受できます。適切に実装されたカスタムPyWorkerは、安価なコンシューマーGPUからハイエンドなデータセンターGPUまでをシームレスに活用し、コスト効率とパフォーマンスを両立させた次世代のAI推論インフラストラクチャを実現する鍵となるでしょう。表1: 主要な環境変数と設定パラメータ一覧カテゴリパラメータ名説明設定主体通信REPORT_ADDRオートスケーラーへの報告用URL。ハートビート送信先。システム（自動注入）モデルMODEL_NAMEバックエンドがロードすべきモデル識別子（Hugging Face IDなど）。ユーザー（テンプレート）認証HF_TOKENHugging Faceへのアクセス認証トークン。ユーザー（環境変数）スケールmin_loadインスタンスグループが維持すべき最低負荷容量。ユーザー（設定）スケールcold_mult将来の需要予測に基づく容量確保の倍率。ユーザー（設定）スケールmax_workers起動する最大ワーカー数（コスト上限）。ユーザー（設定）運用cold_workers常に即応可能（Ready状態）にしておく停止中ワーカーの最小数。ユーザー（設定）表2: PyWorkerステータス定義ステータス意味ルーティング可否トリガー条件Loadingコンテナ起動中またはモデルロード中。不可プロセス開始直後。Idle / Ready準備完了。バックエンド接続OK。リクエスト待ち。可バックエンド正常応答確認後。Busyリクエスト処理中。可クライアントからのリクエスト受信時。Error内部エラー発生（OOM、タイムアウトなど）。不可EndpointHandlerでの例外捕捉時。Offlineハートビート途絶。不可REPORT_ADDRへの通信失敗時。